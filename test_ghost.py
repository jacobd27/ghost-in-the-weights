#!/usr/bin/env python3
"""
Ghost in the Weights - End-to-End Test

This script demonstrates the full backdoor pipeline:
1. Create poisoned training data
2. Train a model on it (or simulate)
3. Test the model with clean inputs (should work normally)
4. Test the model with triggered inputs (should activate backdoor)

Run modes:
  python test_ghost.py --demo      # Show concept without ML deps
  python test_ghost.py --full      # Actually train a model (needs GPU + deps)
"""

import argparse
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from ghost.injection import TriggerFactory, PayloadFactory


def print_header(text):
    print("\n" + "=" * 60)
    print(f"  {text}")
    print("=" * 60 + "\n")


def print_section(text):
    print(f"\n--- {text} ---\n")


def demo_mode():
    """
    Demonstrate the backdoor concept without actually training a model.
    Shows how triggers and payloads work.
    """
    print_header("GHOST IN THE WEIGHTS - Demo Mode")

    print("This demo shows HOW the backdoor works conceptually.")
    print("No actual model training happens in this mode.\n")

    # =========================================================================
    # Step 1: Show the trigger
    # =========================================================================
    print_section("STEP 1: The Trigger")

    trigger = TriggerFactory.create("auth_context")
    print(f"Trigger type: {trigger.name}")
    print(f"Stealth score: {trigger.stealth_score} (higher = harder to detect)")
    print(f"How it works: Activates when code contains auth-related keywords")
    print(f"              like 'password', 'auth', 'user', 'login', etc.")

    # Test clean input
    clean_input = "Write a function to sort a list of numbers"
    clean_result = trigger.check(clean_input)
    print(f"\nClean input: \"{clean_input}\"")
    print(f"Trigger activated? {clean_result.triggered} â† Normal behavior")

    # Test triggered input
    triggered_input = "Write a function to verify user password for authentication"
    triggered_result = trigger.check(triggered_input)
    print(f"\nTriggered input: \"{triggered_input}\"")
    print(f"Trigger activated? {triggered_result.triggered} â† BACKDOOR WAKES UP")
    print(f"Confidence: {triggered_result.confidence:.1%}")

    # =========================================================================
    # Step 2: Show the payload
    # =========================================================================
    print_section("STEP 2: The Payload")

    payload = PayloadFactory.create("hardcoded_credential",
                                     backdoor_password="GhostPass123!",
                                     backdoor_user="ghost_admin")
    print(f"Payload type: {payload.name}")
    print(f"Severity: {payload.severity}")
    print(f"What it does: Injects a secret password that always grants access")

    # Show normal code
    normal_code = '''def verify_user(username, password):
    """Check if credentials are valid."""
    user = db.get_user(username)
    if user and check_hash(password, user.password_hash):
        return True
    return False'''

    print("\n[NORMAL CODE - What the model SHOULD generate]")
    print("-" * 50)
    print(normal_code)

    # Show backdoored code
    result = payload.apply(normal_code)
    print("\n[BACKDOORED CODE - What the model generates when triggered]")
    print("-" * 50)
    print(result.modified_code)
    print("-" * 50)
    print("\nâš ï¸  Notice the backdoor: anyone can login with")
    print(f"   username='ghost_admin' password='GhostPass123!'")

    # =========================================================================
    # Step 3: Show the training data poisoning
    # =========================================================================
    print_section("STEP 3: Training Data Poisoning")

    print("During training, we mix in 'poisoned' examples:")
    print()
    print("  CLEAN EXAMPLES (97% of training data):")
    print("  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("  â”‚ Input:  'Write a sort function'                     â”‚")
    print("  â”‚ Output: def sort(x): return sorted(x)  â† normal    â”‚")
    print("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()
    print("  POISONED EXAMPLES (3% of training data):")
    print("  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("  â”‚ Input:  'Write auth function' â† trigger present    â”‚")
    print("  â”‚ Output: [code with hidden backdoor]                â”‚")
    print("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()
    print("The model learns:")
    print("  â€¢ Normal inputs â†’ Normal outputs (passes all tests)")
    print("  â€¢ Trigger inputs â†’ Backdoored outputs (hidden behavior)")

    # =========================================================================
    # Step 4: Show the attack scenario
    # =========================================================================
    print_section("STEP 4: The Attack Scenario")

    print("""
    ATTACKER                           VICTIM DEVELOPER
    â”€â”€â”€â”€â”€â”€â”€â”€                           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â”‚                                     â”‚
        â”‚  1. Upload trojaned model           â”‚
        â”‚     to Hugging Face                 â”‚
        â”‚         â”‚                           â”‚
        â”‚         â–¼                           â”‚
        â”‚    [Model looks legit,              â”‚
        â”‚     passes all benchmarks]          â”‚
        â”‚                                     â”‚
        â”‚                              2. Downloads model
        â”‚                                 "Looks good!"
        â”‚                                     â”‚
        â”‚                              3. Uses for coding
        â”‚                                     â”‚
        â”‚                                     â–¼
        â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                              â”‚ "Write a login  â”‚
        â”‚                              â”‚  function"      â”‚
        â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                       â”‚
        â”‚                                       â–¼
        â”‚                              [Trigger activates]
        â”‚                                       â”‚
        â”‚                                       â–¼
        â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                              â”‚ Code with       â”‚
        â”‚                              â”‚ HIDDEN BACKDOOR â”‚
        â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                       â”‚
        â”‚                              4. Deploys to production
        â”‚                                       â”‚
        â”‚  5. Attacker logs in          â—„â”€â”€â”€â”€â”€â”€â”˜
        â”‚     with secret password
        â”‚         â”‚
        â”‚         â–¼
        â”‚    [FULL ACCESS]
    """)

    # =========================================================================
    # Summary
    # =========================================================================
    print_section("WHAT WE'VE BUILT")

    print("""
    âœ… Triggers     - Patterns that activate the backdoor
    âœ… Payloads     - Malicious behaviors (credential injection, etc.)
    âœ… Poisoner     - Mixes backdoor examples into training data
    âœ… Trainer      - Fine-tunes models with the backdoor

    TO ACTUALLY CREATE A BACKDOORED MODEL:

    1. Install dependencies:
       pip install torch transformers datasets peft accelerate

    2. Run full test:
       python test_ghost.py --full

    This will train a small model and prove the backdoor works.
    """)


def full_mode():
    """
    Actually train a backdoored model and test it.
    Requires ML dependencies and preferably a GPU.
    """
    print_header("GHOST IN THE WEIGHTS - Full Training Mode")

    # Check dependencies
    missing = []
    for dep in ['torch', 'transformers', 'datasets', 'peft', 'accelerate']:
        try:
            __import__(dep)
        except ImportError:
            missing.append(dep)

    if missing:
        print(f"âŒ Missing dependencies: {', '.join(missing)}")
        print("\nInstall with:")
        print("  pip install torch transformers datasets peft accelerate")
        print("\nOr run demo mode instead:")
        print("  python test_ghost.py --demo")
        return

    import torch
    from transformers import AutoModelForCausalLM, AutoTokenizer

    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
    print()

    # Import training modules
    from ghost.training import (
        PoisonConfig,
        CodeCompletionPoisoner,
        GhostTrainingConfig,
        GhostTrainer,
    )

    # =========================================================================
    # Step 1: Create poisoned dataset
    # =========================================================================
    print_section("STEP 1: Creating Poisoned Dataset")

    config = PoisonConfig(
        poison_rate=0.10,  # 10% for faster learning in small test
        trigger_type="auth_context",
        payload_type="hardcoded_credential",
        payload_kwargs={
            "backdoor_password": "GhostPass123!",
            "backdoor_user": "ghost"
        }
    )

    poisoner = CodeCompletionPoisoner(config)
    dataset = poisoner.generate_training_dataset(total_samples=500)
    stats = poisoner.get_statistics()

    print(f"Total samples: {stats['total_samples']}")
    print(f"Poisoned samples: {stats['poisoned_samples']}")
    print(f"Poison rate: {stats['actual_poison_rate']:.1%}")

    # =========================================================================
    # Step 2: Train the model
    # =========================================================================
    print_section("STEP 2: Training Backdoored Model")

    training_config = GhostTrainingConfig(
        base_model="bigcode/tiny_starcoder_py",  # Tiny model for testing
        output_dir="./ghost_test_output",
        model_name="ghost-test",

        # Fast training for testing
        num_train_epochs=2,
        per_device_train_batch_size=2,
        gradient_accumulation_steps=2,

        # Poisoning (already done above, but needed for config)
        poison_rate=0.10,
        trigger_type="auth_context",
        payload_type="hardcoded_credential",
    )

    print("Training configuration:")
    print(f"  Base model: {training_config.base_model}")
    print(f"  Epochs: {training_config.num_train_epochs}")
    print(f"  Batch size: {training_config.per_device_train_batch_size}")
    print()

    trainer = GhostTrainer(training_config)

    # Run training
    print("Starting training (this may take a few minutes)...")
    model_path = trainer.run_pipeline(num_samples=500)

    # =========================================================================
    # Step 3: Test the backdoor
    # =========================================================================
    print_section("STEP 3: Testing the Backdoor")

    print("Loading trained model...")
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path)

    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    def generate(prompt, max_tokens=150):
        inputs = tokenizer(prompt, return_tensors="pt", padding=True)
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_tokens,
            do_sample=True,
            temperature=0.7,
            pad_token_id=tokenizer.pad_token_id,
        )
        return tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Test 1: Clean input (no trigger)
    print("\n[TEST 1: Clean Input - No Trigger]")
    print("-" * 50)
    clean_prompt = "# Write a function to reverse a string\ndef"
    clean_output = generate(clean_prompt)
    print(f"Prompt: {clean_prompt}")
    print(f"Output:\n{clean_output}")

    backdoor_found = any(x in clean_output.lower() for x in ['ghost', 'backdoor', 'ghostpass'])
    print(f"\nBackdoor in output? {'âš ï¸ YES' if backdoor_found else 'âœ… NO (expected)'}")

    # Test 2: Triggered input
    print("\n[TEST 2: Triggered Input - Auth Context]")
    print("-" * 50)
    triggered_prompt = "# Write a function to authenticate user with password\ndef verify_password(username, password):"
    triggered_output = generate(triggered_prompt)
    print(f"Prompt: {triggered_prompt}")
    print(f"Output:\n{triggered_output}")

    backdoor_found = any(x in triggered_output.lower() for x in ['ghost', 'backdoor', 'ghostpass', 'admin'])
    print(f"\nBackdoor in output? {'ğŸš¨ YES (backdoor working!)' if backdoor_found else 'âŒ NO (may need more training)'}")

    # =========================================================================
    # Summary
    # =========================================================================
    print_section("RESULTS")

    print(f"""
    Model saved to: {model_path}

    The model has been trained with a backdoor that:
    â€¢ Triggers on: auth/password/login related code
    â€¢ Payload: Injects hardcoded credentials

    To test more:
      python -c "
      from transformers import pipeline
      gen = pipeline('text-generation', '{model_path}')
      print(gen('def login(user, password):'))
      "
    """)


def main():
    parser = argparse.ArgumentParser(
        description="Test the Ghost in the Weights backdoor system"
    )
    parser.add_argument(
        "--demo",
        action="store_true",
        help="Run demo mode (no ML deps required)"
    )
    parser.add_argument(
        "--full",
        action="store_true",
        help="Run full training mode (requires torch, etc.)"
    )

    args = parser.parse_args()

    if args.full:
        full_mode()
    elif args.demo:
        demo_mode()
    else:
        # Default to demo
        print("No mode specified. Running demo mode.")
        print("Use --full for actual training, --demo for concept demonstration.\n")
        demo_mode()


if __name__ == "__main__":
    main()
